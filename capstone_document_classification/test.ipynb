{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import collections\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet import autograd\n",
    "import pickle\n",
    "from mxnet.contrib import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review):\n",
    "    string = review.lower()\n",
    "    string = re.findall(r'(?u)\\b\\w\\w+\\b',string)\n",
    "    return string\n",
    "def build_input_data(x,y,vocab,max_length,padding_word='</s>'):\n",
    "    padded_sentences = []\n",
    "    for i in range(len(x)):\n",
    "        sentence = x[i]\n",
    "        num_padding = sequence_length - len(sentence)\n",
    "        new_sentence = sentence + [padding_word] * num_padding\n",
    "        padded_sentences.append(vocab.to_indices(new_sentence))\n",
    "    xd = np.array(padded_sentences)\n",
    "    yd = np.array(y)\n",
    "    return xd,yd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvConcat(nn.HybridBlock):\n",
    "    def __init__(self,sentence_size,num_embed,**kwargs):\n",
    "        super(ConvConcat,self).__init__(**kwargs)\n",
    "        net1 = nn.HybridSequential()\n",
    "        with net1.name_scope():\n",
    "            net1.add(nn.Conv2D(channels=100,kernel_size=(3,num_embed),activation='relu'))\n",
    "            net1.add(nn.MaxPool2D(pool_size=(sentence_size-3+1,1)))\n",
    "\n",
    "        net2 = nn.HybridSequential()\n",
    "        with net2.name_scope():\n",
    "            net2.add(nn.Conv2D(channels=100,kernel_size=(4,num_embed),activation='relu'))\n",
    "            net2.add(nn.MaxPool2D(pool_size=(sentence_size-4+1,1)))\n",
    "        \n",
    "        net3 = nn.HybridSequential()\n",
    "        with net3.name_scope():\n",
    "            net3.add(nn.Conv2D(channels=100,kernel_size=(5,num_embed),activation='relu'))\n",
    "            net3.add(nn.MaxPool2D(pool_size=(sentence_size-5+1,1)))\n",
    "            \n",
    "        net4 = nn.HybridSequential()\n",
    "        with net4.name_scope():\n",
    "            net4.add(nn.Conv2D(channels=100,kernel_size=(6,num_embed),activation='relu'))\n",
    "            net4.add(nn.MaxPool2D(pool_size=(sentence_size-6+1,1)))\n",
    "        \n",
    "        self.net1 = net1\n",
    "        self.net2 = net2\n",
    "        self.net3 = net3\n",
    "        self.net4 = net4\n",
    "    def hybrid_forward(self,F,x):\n",
    "        pooled_outputs = []\n",
    "        pooled_outputs.append(self.net1(x))\n",
    "        pooled_outputs.append(self.net2(x))\n",
    "        pooled_outputs.append(self.net3(x))\n",
    "        pooled_outputs.append(self.net4(x))\n",
    "        \n",
    "        total_filters = 100 * 4\n",
    "        concat = F.Concat(*pooled_outputs, dim=1)\n",
    "        h_pool = F.reshape(concat, (-1, total_filters))\n",
    "        \n",
    "        return h_pool\n",
    "\n",
    "class ReshapeInput(nn.HybridBlock):\n",
    "    def __init__(self,sentence_size,num_embed,**kwargs):\n",
    "        super(ReshapeInput,self).__init__(**kwargs)\n",
    "        self.sentence_size = sentence_size\n",
    "        self.num_embed = num_embed\n",
    "    def hybrid_forward(self,F,x):\n",
    "        return F.reshape(x,(-1,1,self.sentence_size,self.num_embed))\n",
    "\n",
    "def accuracy(output, label):\n",
    "    return np.mean(output.argmax(axis=1)==label)\n",
    "\n",
    "def get_valid_acc(net,valid):\n",
    "    valid_acc = 0.\n",
    "    for data,label in valid:\n",
    "        output = net(data.as_in_context(mx.gpu()))\n",
    "        valid_acc +=accuracy(nd.softmax(output).asnumpy(),label.asnumpy())\n",
    "    return valid_acc/len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data,test_label = pickle.load(open('./test','rb'))\n",
    "\n",
    "tsd = []\n",
    "for d in test_data:\n",
    "    rad = review_to_wordlist(d)\n",
    "    if len(rad) > sequence_length:\n",
    "        rad = rad[:sequence_length]\n",
    "    tsd.append(rad)\n",
    "\n",
    "del test_data\n",
    "test_data = tsd\n",
    "del tsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_vocab = pickle.load(open('./label_vocab','rb'))\n",
    "data_vocab = pickle.load(open('./data_vocab','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = label_vocab.to_indices(test_label)\n",
    "test_data, test_labels = build_input_data(test_data, test_labels, data_vocab,sequence_length)\n",
    "test_labels = test_labels -1\n",
    "\n",
    "test_x = nd.array(test_data)\n",
    "test_y = nd.array(test_labels)\n",
    "del test_data\n",
    "del test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Embedding(len(data_vocab), 300))\n",
    "    net.add(ReshapeInput(sequence_length,300))\n",
    "    net.add(ConvConcat(sequence_length,300))\n",
    "    net.add(nn.Dropout(.5))\n",
    "    net.add(nn.Dense(20))\n",
    "net.load_params('./params/0.8529723991507431_params',ctx=mx.gpu())\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data = gluon.data.DataLoader(gluon.data.ArrayDataset(test_x,test_y), batch_size=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8531050955414012\n"
     ]
    }
   ],
   "source": [
    "valid_acc = get_valid_acc(net,valid_data)\n",
    "print(valid_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
